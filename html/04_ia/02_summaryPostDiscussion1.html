<!DOCTYPE HTML>
<html>
	<head>
		<title>Alberto Castro</title>
		<link rel="icon" type="image/x-icon" href="images/favicon.ico">
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="../../assets/css/main.css" />
	</head>
	<body class="is-preload">
        <h3>Agent Based Systems - Summary Post</h3>
        <p>

			The discussion about recommender systems was meaningful and introduced a contrast between AI systems' advantages and dark sides. Recommender systems have indeed given many benefits to organizations and companies, such as improvements in user experience to their users and in unit economics and metrics (Castro, 2023). However, on the darker side, they have trade-offs like the ones mentioned by my fellow student Vasilisa. One of the examples she provided about YouTube facilitating content to pedophiles sounds very dangerous (Lukashevich, 2023), and I imagine such groups can exploit other systems or websites like YouTube.
<br>
<br>
			Additionally, Vasilisa mentioned systems being sexist and racist. I had discussed this in a different module, where Amazon used an internal machine learning model they developed to filter engineering candidates. Still, it resulted in biased predictions favoring only male candidates (Castro, 2023). Machine intelligent agents, machine learning models, or any other technology that learns from experience (from experiences created by humans) will also learn the dark side of users. A great example of this can be seen with a project deployed by Microsoft using Twitter, where they developed and deployed a bot capable of learning from users and interacting with them. Initially, Microsoft stated that this project was designed to engage and entertain people, but it became a racist bot (Victor, 2016).
<br>
<br>
			In conclusion, AI (This covers intelligent agents, natural language processing, machine learning models, or any other AI-based system) is a powerful tool if used correctly, but to use it correctly, I believe we must spend time and effort to anticipate and mitigate the trade-offs that can become very dangerous, and we must always have in mind that there will be users willing to try to exploit hidden vulnerabilities in AI-based systems.
<br><br>
References
<br><br>
			Castro, A. (2023) Initial Post. Collaborative Discussion 1: Agent Based Systems in Intelligent Agents May 2023 module. The University of Essex Online. Available from: https://www.my-course.co.uk/mod/forum/discuss.php?d=156865 [Accessed 21 May 2023].
<br>
<br>
			Castro, A. (2023) Initial Post. Collaborative Discussion 1: The 4th Industrial Revolution in Machine Learning Jan 2023 module. The University of Essex Online. Available from:  https://www.my-course.co.uk/mod/forum/discuss.php?d=136754 [Accessed 21 May 2023].
			<br>
			<br>
			Lukashevich, V. (2023) Peer Response: Bias in Recommender Systems in Intelligent Agents May 2023 module. The University of Essex Online. Available from: https://www.my-course.co.uk/mod/forum/discuss.php?d=156865#p241557 [Accessed 21 May 2023].
			<br>
			<br>
			Victor, D. (2016). Microsoft created a Twitter bot to learn from users. It quickly became a racist jerk. The New York Times. Available at: https://www.nytimes.com/2016/03/25/technology/microsoft-created-a-twitter-bot-to-learn-from-users-it-quickly-became-a-racist-jerk.html [Accessed 21 May 2023].
        </p>
    </body>
</html>

